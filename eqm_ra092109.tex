\documentclass[12pt,twoside,a4paper]{article}
\usepackage[brazil,english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{timbre-ic}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{url}

\begin{document}

\vskip 15mm

\begin{center}
\textbf{Nonblocking Treplica}
\end{center}

\vskip 5mm

\textbf{Orientando:} Lu√≠sa Madeira Cardoso

\textbf{Orientador:} Luiz Eduardo Buzato

\vskip 20mm

\begin{abstract}

\end{abstract}

% resetando configs de layout
\newpage
\pagestyle{plain}
\headheight 0.0cm
\headsep 0.0cm
\footskip 2.2cm

\section{Introduction}
One of the critical aspects of implementing total order broadcast (TOB) is how
concurrency is handled. Simultaneous events are in the very nature of such
algorithms; they need to receive and transmit messages, handle internal
interruptions, and deal with data persistence. Usually those asynchronous
concurrent parts are organized by several threads that share data. The access to
those mutual structures must be done carefully by taking into consideration the
possibility of parallel writes. If a strict discipline is not followed, an
incorrect and undesirable state might be produced.

The primary mechanism used in those scenarios is exclusive locking - also called
busy waiting, conditional waiting or critical sections. Unfortunately, any
locking-based synchronization technique can lead  to arbitrary delays: if the
critical section owner is slow, then all others will be too. This is a very
undesirable effect for a TOB implementation.

To try to circumvent the problem, Lamport introduced in 1977 the first algorithms
for concurrent reading and writing without the use of locks \cite{lamport77b}.
The idea was later developed by Herlihy into a body of mechanisms that support
lock-freedom and wait-freedom \cite{herlihy1990methodology}. Wait-freedom
guarantees that any process that accesses a shared concurrent  object will
complete its operation in a finite number of steps, regardless  the execution
speed of the other processes. In contrast, lock-freedom is weaker and only
assures that \textit{some} process will terminate in a finite number of steps.
The first implies that a thread will make progress despite of others being very
or slow even completely stopped; the later implies a global progress condition.

Wait-freedom is a very  desirable property when one has to cope with threads
that encounter unexpected delays; this  is the case
of  most  implementations of  consensus-based  TOBs.

Treplica \cite{vieira2008} is a tool that provides TOB through Fast-Paxos
\cite{Lamport2006}. It handles concurrency by using the traditional
synchronization mechanisms: locks. During our research we are going to transform
its current implementation  into a functionally equivalent lock-free version.
The  performance of the two will be compared using micro benchmarks to assess
the contribution  of nonblocking mechanisms to the  performance of active
replication.


\section{Related Work}
\label{sec:related}

Nonblocking data structures are the foundations of this work. They designate
objects that are shared by concurrent processes and guarantee the global
progression of the system. More precisely, they  assure that some process will
complete an operation in a finite number of steps, regardless of the relative
speed of others; one process will never block the other, even if it fails or is
slow. Note that this  property cannot be achieved by assuring that a single
process at a time manipulates the object: the current owner of the critical
section might halt, leaving all others waiting.

These structures have been widely studied in the last decades, since they are
the heart of many important problems in the concurrent programming area
\cite{herlihy2011art}.

The name "wait-free" may give the impression that such implementations are
faster than its blocking counterparts. However, this notion is misleading.  Such
algorithms can be complex and inefficient \cite{attiya1994wait}.

Java provides a wait-free queue called \textit{ConcurrentLinkedQueue} that is
based on a work by Michael and Scott \cite{michael1996simple}. This
implementation was very promising because it showed the best performance in
comparison to other blocking and nonblocking counterparts in the preliminary
results presented by the authors.


\section{Expected Contribution}
\label{sec:contrib}



\section{Schedule}
\label{sec:schedule}


\vskip 15mm

\bibliography{refs}{}
\bibliographystyle{acm}

\end{document}

